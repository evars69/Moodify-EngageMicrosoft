{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKRMS0QP5rIp"
      },
      "source": [
        "# **Downloading Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AH8g3tMhyDF",
        "outputId": "db9557db-e026-41c8-e446-a6f83decc1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.12)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (2022.5.18.1)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: urllib3 in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (1.26.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: colorama in c:\\users\\barsha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->kaggle) (0.4.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\BARSHA\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n",
            "The syntax of the command is incorrect.\n",
            "'cp' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'chmod' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\users\\barsha\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"c:\\users\\barsha\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"C:\\Users\\BARSHA\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\kaggle.exe\\__main__.py\", line 4, in <module>\n",
            "  File \"c:\\users\\barsha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\kaggle\\__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"c:\\users\\barsha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 164, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in C:\\Users\\BARSHA\\.kaggle. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "%pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FFPSFnI_Qvu"
      },
      "source": [
        "#**Unzipping the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYy1Inzh7yle",
        "outputId": "acebfc98-5b5d-4c13-9148-da0ceb8a5f40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'%unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!%unzip face-expression-recognition-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBybnKiEP1kj"
      },
      "source": [
        "#**Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "thBLz8Wo9uFJ"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000006?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000006?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator , img_to_array, load_img\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input \n",
        "from keras.losses import categorical_crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYrSECB4_nTG"
      },
      "source": [
        "#**Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rskmL3tL91nL",
        "outputId": "44e810e6-73ae-409d-96a6-aaeec7cf2c5d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ImageDataGenerator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=0'>1</a>\u001b[0m train_datagen \u001b[39m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=1'>2</a>\u001b[0m      zoom_range \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=2'>3</a>\u001b[0m      shear_range \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=3'>4</a>\u001b[0m      horizontal_flip\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=4'>5</a>\u001b[0m      rescale \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=5'>6</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=7'>8</a>\u001b[0m train_data \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39mflow_from_directory(directory\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/content/images/images/train\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=8'>9</a>\u001b[0m                                                target_size\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=9'>10</a>\u001b[0m                                                batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=10'>11</a>\u001b[0m                                   )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000008?line=13'>14</a>\u001b[0m train_data\u001b[39m.\u001b[39mclass_indices\n",
            "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "     zoom_range = 0.2, \n",
        "     shear_range = 0.2, \n",
        "     horizontal_flip=True, \n",
        "     rescale = 1./255\n",
        ")\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(directory= \"/content/images/images/train\", \n",
        "                                               target_size=(224,224), \n",
        "                                               batch_size=32,\n",
        "                                  )\n",
        "\n",
        "\n",
        "train_data.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW8uws4T_vAs"
      },
      "source": [
        "#**Testing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDCQvvQB99gU",
        "outputId": "bf6dd289-5f01-4675-8f70-ea56769ad0fb"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ImageDataGenerator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000010?line=0'>1</a>\u001b[0m val_datagen \u001b[39m=\u001b[39m ImageDataGenerator(rescale \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000010?line=2'>3</a>\u001b[0m val_data \u001b[39m=\u001b[39m val_datagen\u001b[39m.\u001b[39mflow_from_directory(directory\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/content/images/images/validation\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000010?line=3'>4</a>\u001b[0m                                            target_size\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000010?line=4'>5</a>\u001b[0m                                            batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000010?line=5'>6</a>\u001b[0m val_data\u001b[39m.\u001b[39mclass_indices\n",
            "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ],
      "source": [
        "val_datagen = ImageDataGenerator(rescale = 1./255 )\n",
        "\n",
        "val_data = val_datagen.flow_from_directory(directory= \"/content/images/images/validation\", \n",
        "                                           target_size=(224,224), \n",
        "                                           batch_size=32)\n",
        "val_data.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbq3poyV7035"
      },
      "source": [
        "# **Visualize the images in the training data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1ncF6i_5-FiX",
        "outputId": "e911f213-ee23-4fdf-e580-e6141bb6eddd"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000012?line=0'>1</a>\u001b[0m t_img , label \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mnext()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000012?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplotImages\u001b[39m(img_arr, label):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000012?line=3'>4</a>\u001b[0m   count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ],
      "source": [
        "t_img , label = train_data.next()\n",
        "\n",
        "def plotImages(img_arr, label):\n",
        "  count = 0\n",
        "  for im, l in zip(img_arr,label) :\n",
        "    plt.imshow(im)\n",
        "    plt.title(im.shape)\n",
        "    plt.axis = False\n",
        "    plt.show()\n",
        "    \n",
        "    count += 1\n",
        "    if count == 10:\n",
        "      break\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "# function call to plot the images \n",
        "plotImages(t_img, label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5JOFZkP6cET"
      },
      "source": [
        "#**Using MobileNet for its pre-trained weights**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OeNB5eR9wgh"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'MobileNet' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000014?line=0'>1</a>\u001b[0m base_model \u001b[39m=\u001b[39m MobileNet( input_shape\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m,\u001b[39m3\u001b[39m), include_top\u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000014?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m base_model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000014?line=3'>4</a>\u001b[0m   layer\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'MobileNet' is not defined"
          ]
        }
      ],
      "source": [
        "base_model = MobileNet( input_shape=(224,224,3), include_top= False )\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(units=7 , activation='softmax' )(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPW8bM8P7Llo"
      },
      "source": [
        "# **Creating our model.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO4oE16l9ypB"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000016?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Model(base_model\u001b[39m.\u001b[39minput, x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000016?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m categorical_crossentropy , metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]  )\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Model' is not defined"
          ]
        }
      ],
      "source": [
        "model = Model(base_model.input, x)\n",
        "model.compile(optimizer='adam', loss= categorical_crossentropy , metrics=['accuracy']  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWeObdWE770n"
      },
      "source": [
        "#**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf5T1FVB-TiV",
        "outputId": "38af7adb-77cf-44ed-f766-211a85a81dc2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000018?line=0'>1</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit_generator(train_data, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000018?line=1'>2</a>\u001b[0m                            steps_per_epoch\u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000018?line=2'>3</a>\u001b[0m                            epochs\u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000018?line=3'>4</a>\u001b[0m                            validation_data\u001b[39m=\u001b[39m val_data, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000018?line=4'>5</a>\u001b[0m                            validation_steps\u001b[39m=\u001b[39m \u001b[39m10\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "hist = model.fit_generator(train_data, \n",
        "                           steps_per_epoch= 10, \n",
        "                           epochs= 100, \n",
        "                           validation_data= val_data, \n",
        "                           validation_steps= 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffu48A4gAp2t"
      },
      "source": [
        "#**Saving the built Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4caHqjnokbr6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000020?line=0'>1</a>\u001b[0m \u001b[39m# Save the model in h5 format \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000020?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mfinal_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# Save the model in h5 format \n",
        "model.save('final_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDLR95l7Auzl"
      },
      "source": [
        "#**Train accuracy v/s Testing accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "K8l0OodF-8Ur",
        "outputId": "112e545f-db75-4f99-e606-3a701c071271"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000022?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000022?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m] , c \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mred\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000022?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mtraining_acc vs validation_acc\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'] , c = \"red\")\n",
        "plt.title(\"training_acc vs validation_acc\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgh47EM5KWyw"
      },
      "source": [
        "#**Training Loss v/s Testing Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "hyLS4dCh-_Zy",
        "outputId": "bbf31bd2-4c52-4e0d-98dc-edd3910b4b63"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000024?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000024?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m] , c \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mred\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000024?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mtrain_loss vs validation_loss\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'] , c = \"red\")\n",
        "plt.title(\"train_loss vs validation_loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQzYKyNB8aBQ"
      },
      "source": [
        "# **Testing the model using images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7U7W_4d_Aiz"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 27'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000026?line=0'>1</a>\u001b[0m op \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m( train_data\u001b[39m.\u001b[39mclass_indices\u001b[39m.\u001b[39mvalues(), train_data\u001b[39m.\u001b[39mclass_indices\u001b[39m.\u001b[39mkeys()))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ],
      "source": [
        "op = dict(zip( train_data.class_indices.values(), train_data.class_indices.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "uVSHne1A_FFj",
        "outputId": "bf55d12c-a850-4a40-ffbf-5ebc4b8cce8e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'load_img' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\BARSHA\\Face_Recognition_VK\\Emotion_Detection.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000027?line=0'>1</a>\u001b[0m \u001b[39m# path for the image to see if it predics correct class\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000027?line=2'>3</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/content/images/images/validation/angry/10052.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000027?line=3'>4</a>\u001b[0m img \u001b[39m=\u001b[39m load_img(path, target_size\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m) )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000027?line=5'>6</a>\u001b[0m i \u001b[39m=\u001b[39m img_to_array(img)\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/BARSHA/Face_Recognition_VK/Emotion_Detection.ipynb#ch0000027?line=6'>7</a>\u001b[0m input_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([i])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'load_img' is not defined"
          ]
        }
      ],
      "source": [
        "# path for the image to see if it predics correct class\n",
        "\n",
        "path = \"/content/images/images/validation/angry/10052.jpg\"\n",
        "img = load_img(path, target_size=(224,224) )\n",
        "\n",
        "i = img_to_array(img)/255\n",
        "input_arr = np.array([i])\n",
        "input_arr.shape\n",
        "\n",
        "pred = np.argmax(model.predict(input_arr))\n",
        "\n",
        "print(f\" the image is of {op[pred]}\")\n",
        "\n",
        "# to display the image  \n",
        "plt.imshow(input_arr[0])\n",
        "plt.title(\"input image\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Emotion Detection.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "1031793fd9f9fd42383ea478d8105c2605fd4de4334d9ff201ee8971c6e2dab7"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
